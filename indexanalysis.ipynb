{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d0f427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.11.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## To import necessary python libraries\n",
    "from nsepy import get_history\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import cufflinks as cf\n",
    "import plotly.io as pio \n",
    "\n",
    "cf.go_offline()\n",
    "cf.set_config_file(world_readable=True, theme='pearl')\n",
    "pio.renderers.default = \"notebook\" # should change by looking into pio.renderers\n",
    "\n",
    "## To display multiple output from one cell without overwriting the first\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12c1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NSE data reading using nsepy get_history module\n",
    "# Function get_history fetches the price history of stocks/indices/derivatives and returns a pandas dataframe\n",
    "# symbol = ['NIFTY 50', 'NIFTY AUTO', 'NIFTY IT', 'NIFTY BANK', 'NIFTY PHARMA','INDIA VIX', ]\n",
    "# end = datetime.datetime.now()\n",
    "# start = datetime.datetime(end.year-22,end.month-7,end.day-27)\n",
    "\n",
    "# data1={}\n",
    "# for s in (symbol):  \n",
    "#     data=get_history(symbol=s,start=start, end=end, index=True) ## to read stocks remove the index=True command.\n",
    "#     data.to_csv(f'{s}.csv', sep=',')\n",
    "#     data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf190f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dataframe with different stocks data\n",
    "# end = datetime.datetime.now()\n",
    "# start = datetime.datetime(end.year-22,end.month-7,end.day-27)\n",
    "# data = {}\n",
    "# symbol = ['^N225', '^HSI']\n",
    "# for s in (symbol):  \n",
    "#     data = web.DataReader(s,'yahoo', start = start, end = end)\n",
    "#     data.to_csv(f'{s}.csv', sep=',')\n",
    "#     data ={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba3bc99",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NIFTY 50.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pl/g5kg5m5d06q_z_dgyvpv_84w0000gn/T/ipykernel_27285/4052473015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To create seperate dataframes with stock data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNIFTY_50_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NIFTY 50.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mNIFTY_AUTO_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NIFTY AUTO.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mNIFTY_IT_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NIFTY IT.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNIFTY_BANK_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NIFTY BANK.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NIFTY 50.csv'"
     ]
    }
   ],
   "source": [
    "# To create seperate dataframes with stock data\n",
    "NIFTY_50_df = pd.read_csv('NIFTY 50.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "NIFTY_AUTO_df = pd.read_csv('NIFTY AUTO.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "NIFTY_IT_df = pd.read_csv('NIFTY IT.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "NIFTY_BANK_df = pd.read_csv('NIFTY BANK.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "NIFTY_PHARMA_df = pd.read_csv('NIFTY PHARMA.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "INDIA_VIX_df = pd.read_csv('INDIA VIX.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "N225_df = pd.read_csv('N225.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "HSI_df = pd.read_csv('HSI.csv', usecols=['Date', 'Close'], parse_dates=['Date'], index_col=['Date'])\n",
    "\n",
    "NIFTY_50_df.rename(columns={'Close': 'NIFTY50'}, inplace=True)\n",
    "NIFTY_IT_df.rename(columns={'Close': 'NIFTYIT'}, inplace=True)\n",
    "NIFTY_AUTO_df.rename(columns={'Close': 'NIFTYAUTO'}, inplace=True)\n",
    "NIFTY_BANK_df.rename(columns={'Close': 'NIFTYBANK'}, inplace=True)\n",
    "NIFTY_PHARMA_df.rename(columns={'Close': 'NIFTYPHARMA'}, inplace=True)\n",
    "INDIA_VIX_df.rename(columns={'Close': 'INDIAVIX'}, inplace=True)\n",
    "N225_df.rename(columns={'Close': 'N225'}, inplace=True)\n",
    "HSI_df.rename(columns={'Close': 'HSI'}, inplace=True)\n",
    "\n",
    "# NIFTY_50_df.head(5)\n",
    "# NIFTY_IT_df.head(5)\n",
    "# NIFTY_AUTO_df.head(5)\n",
    "# NIFTY_BANK_df.head(5)\n",
    "# NIFTY_PHARMA_df.head(5)\n",
    "# INDIA_VIX_df.head(5)\n",
    "# N225_df.head(5)\n",
    "# HSI_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cabb360",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining all index data of CLOSE columns into one single dataframe for ease of analysis\n",
    "df  = NIFTY_50_df.merge(NIFTY_IT_df,on = 'Date',how ='outer').merge(NIFTY_AUTO_df, on = 'Date',how ='outer').merge(NIFTY_PHARMA_df, on = 'Date',how ='outer').merge(NIFTY_BANK_df, on = 'Date',how ='outer').merge(INDIA_VIX_df, on = 'Date',how ='outer').merge(N225_df, on = 'Date',how ='outer').merge(HSI_df, on = 'Date',how ='outer')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arrange the data with increasing order of Date\n",
    "df = df.sort_values(by='Date', ascending=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b369e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ('slategrey','rosybrown','firebrick','coral','tan','olive','darkseagreen','steelblue','plum','palevioletred')\n",
    "df.iplot(kind=\"line\",\n",
    "        y=[\"NIFTY50\", \"NIFTYIT\", \"NIFTYAUTO\", \"NIFTYPHARMA\", \"NIFTYBANK\",\"N225\",\"HSI\"],\n",
    "        secondary_y = \"INDIAVIX\",\n",
    "        color=colors,\n",
    "        width=2,\n",
    "        yTitle=\"Close\", \n",
    "        subplots=True,\n",
    "        title=\"Index closing values 2000 TO 2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13080d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ('slategrey','rosybrown','firebrick','coral','tan','olive','darkseagreen','steelblue','plum','palevioletred')\n",
    "df.iplot(kind=\"line\",\n",
    "        y=[\"NIFTY50\", \"NIFTYIT\", \"NIFTYAUTO\", \"NIFTYPHARMA\", \"NIFTYBANK\",\"N225\",\"HSI\"],\n",
    "        secondary_y = \"INDIAVIX\",\n",
    "        color=colors,\n",
    "        width=2,\n",
    "        yTitle=\"Close\", \n",
    "        title=\"Index closing values 2000 TO 2022 All in One plot\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a874e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This table shows correlation of different indexes. \n",
    "##The higher the number the better the correlation\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "## from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n",
    "##DataFrame.corr(method='pearson', min_periods=1)[source]\n",
    "##Compute pairwise correlation of columns, excluding NA/null values.\n",
    "#dfn = dfn.dropna(axis=0) ## this need not be done since for each pair of columns NA values are dropped in the .corr funtions\n",
    "dfp = df.pct_change()*100 \n",
    "corr = dfp.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The pearson coefficient is necessary to validate the correlation numbers \n",
    "## in the correlation table\n",
    "## The pearson coefficient needs to be lower than 0.05.\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    return pvalues\n",
    "\n",
    "calculate_pvalues(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8742113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots of nifty50 with other indexes.\n",
    "\n",
    "fig, axes = plt.subplots(sharey=True, nrows=2, ncols=2)\n",
    "\n",
    "df.NIFTY50.plot(ax=axes[0,0],color=\"grey\",label=\"NIFTY50\", legend=True,ylim=(0, 50000),figsize=(20,20));\n",
    "df.NIFTYIT.plot(ax=axes[0,0],color=\"purple\",label=\"NIFTYIT\", legend=True,figsize=(20,10));\n",
    "\n",
    "df.NIFTY50.plot(ax=axes[0,1],color=\"grey\",label=\"NIFTY50\", legend=True);\n",
    "df.NIFTYBANK.plot(ax=axes[0,1],color=\"dodgerblue\",label=\"NIFTYBANK\", legend=True);\n",
    "\n",
    "df.NIFTY50.plot(ax=axes[1,0],color=\"grey\",label=\"NIFTY50\", legend=True);\n",
    "df.NIFTYAUTO.plot(ax=axes[1,0],color=\"green\",label=\"NIFTYAUTO\", legend=True);\n",
    "\n",
    "df.NIFTY50.plot(ax=axes[1,1],color=\"grey\",label=\"NIFTY50\", legend=True);\n",
    "df.INDIAVIX.plot(ax=axes[1,1],color=\"tomato\",secondary_y=True,label=\"INDIAVIX\", legend=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indexes are treated as seperate dataframes as they have different sizes.\n",
    "#(i.e many indexes are missing lot of data)\n",
    "# finding the r and p values by selecting the columns in the dataframe as a cross verification only.\n",
    "#=========================================\n",
    "#====== run this for verification only====\n",
    "#=========================================\n",
    "df1 = df[['NIFTY50', 'NIFTYIT']]\n",
    "df1p = df1.pct_change()*100\n",
    "df1p = df1p.dropna(axis=0)\n",
    "#df1p.info()\n",
    "\n",
    "df2 = df[['NIFTY50', 'NIFTYAUTO']]\n",
    "df2p = df2.pct_change()*100\n",
    "df2p = df2p.dropna(axis=0)\n",
    "#df2p.info()\n",
    "\n",
    "df3 = df[['NIFTY50', 'NIFTYPHARMA']]\n",
    "df3p = df3.pct_change()*100\n",
    "df3p=df3p.dropna(axis=0)\n",
    "#df3p.info()\n",
    "\n",
    "df4 = df[['NIFTY50', 'NIFTYBANK']]\n",
    "df4p = df4.pct_change()*100\n",
    "df4p=df4p.dropna(axis=0)\n",
    "#df4p.info()\n",
    "\n",
    "df5 = df[['NIFTY50', 'INDIAVIX']]\n",
    "df5p = df5.pct_change()*100\n",
    "df5p=df5p.dropna(axis=0)\n",
    "#df5p.info()\n",
    "\n",
    "df6 = df[['NIFTY50', 'N225']]\n",
    "df6p = df6.pct_change()*100\n",
    "df6p=df6p.dropna(axis=0)\n",
    "#df6p.info()\n",
    "\n",
    "df7 = df[['NIFTY50', 'HSI']]\n",
    "df7p = df7.pct_change()*100\n",
    "df7p = df7p.dropna(axis=0)\n",
    "#df7p.info()\n",
    "\n",
    "res1 = pearsonr(df1p.NIFTY50, df1p.NIFTYIT)\n",
    "res1\n",
    "res2 = pearsonr(df2p.NIFTY50, df2p.NIFTYAUTO)\n",
    "res2\n",
    "res3 = pearsonr(df3p.NIFTY50, df3p.NIFTYPHARMA)\n",
    "res3\n",
    "res4 = pearsonr(df4p.NIFTY50, df4p.NIFTYBANK)\n",
    "res4\n",
    "res5 = pearsonr(df5p.NIFTY50, df5p.INDIAVIX)\n",
    "res5\n",
    "res6 = pearsonr(df6p.NIFTY50, df6p.N225)\n",
    "res6\n",
    "res7 = pearsonr(df7p.NIFTY50, df7p.HSI)\n",
    "res7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce05550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import patchworklib as pw \n",
    "## patchworklib helps in creating jointplots in the form of subplots using \n",
    "#(((g0|g1)[\"g0\"]/g3)[\"g3\"]|g2).savefig(\"seaborn_subplots.png\")\n",
    "sns.set_theme()\n",
    "pw.overwrite_axisgrid() \n",
    "df1p=df1.pct_change()*100\n",
    "df2p=df2.pct_change()*100\n",
    "df3p=df3.pct_change()*100\n",
    "df4p=df4.pct_change()*100\n",
    "df5p=df5.pct_change()*100\n",
    "df6p=df6.pct_change()*100\n",
    "df7p=df7.pct_change()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28892426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## The below plot is from the original individual dataframes to check if data merge and other \n",
    "# ##operations are done well without error\n",
    "\n",
    "# #stock_list = ['NIFTY50', 'NIFTYAUTO', 'NIFTYIT', 'NIFTYBANK', 'NIFTYPHARMA','INDIAVIX','N225', 'HSI']\n",
    "# colors = ('slategrey','rosybrown','firebrick','coral','tan','olive','darkseagreen','steelblue','plum','palevioletred')\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20, 10))\n",
    "\n",
    "# NIFTY_50_df['NIFTY50'].plot(ax=axes[0,0]).title.set_text('NIFTY50')\n",
    "# NIFTY_IT_df['NIFTYIT'].plot(ax=axes[0,1]).title.set_text('NIFTYIT')\n",
    "# NIFTY_AUTO_df['NIFTYAUTO'].plot(ax=axes[1,0]).title.set_text('NIFTYAUTO')\n",
    "# NIFTY_PHARMA_df['NIFTYPHARMA'].plot(ax=axes[1,1]).title.set_text('NIFTYPHARMA')\n",
    "# NIFTY_BANK_df['NIFTYBANK'].plot(ax=axes[2,0]).title.set_text('NIFTYBANK')\n",
    "# INDIA_VIX_df['INDIAVIX'].plot(ax=axes[2,1]).title.set_text('INDIAVIX')\n",
    "# N225_df['N225'].plot(ax=axes[3,0]).title.set_text('N225')\n",
    "# HSI_df['HSI'].plot(ax=axes[3,1]).title.set_text('HSI')\n",
    "\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## plotting pairplot  \n",
    "# # ## Note that the correlation analysis is performed on the daily percentage change(daily returns) \n",
    "# # ## of the stock price and not on the stock price.\n",
    "# import seaborn as sns\n",
    "# dfp = df.pct_change()*100 #for pairplot always calculate pct_change\n",
    "\n",
    "# #dfp.dropna(inplace = True, axis = 0)# not necessary pairplot does this automatically\n",
    "# #dfp.info()\n",
    "# #sns.set(style = 'ticks', font_scale = 1.25)\n",
    "# #sns.pairplot(dfp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scatter plots for visual display of correlation between nifty and other indexes.\n",
    "g0 = sns.jointplot(x='NIFTY50', y='NIFTYIT', data=df1p, kind = 'scatter')\n",
    "g0 = pw.load_seaborngrid(g0, label=\"g0\")\n",
    "g1 = sns.jointplot(x='NIFTY50', y='NIFTYAUTO', data=df2p, kind = 'scatter')\n",
    "g1 = pw.load_seaborngrid(g1, label=\"g1\")\n",
    "g2 = sns.jointplot(x='NIFTY50', y='NIFTYPHARMA', data=df3p, kind = 'scatter')\n",
    "g2 = pw.load_seaborngrid(g2, label=\"g2\")\n",
    "g3 = sns.jointplot(x='NIFTY50', y='NIFTYBANK', data=df4p, kind = 'scatter')\n",
    "g3 = pw.load_seaborngrid(g3, label=\"g3\")\n",
    "#(((g0|g1)[\"g0\"]/g3)[\"g3\"]|g2).savefig(\"seaborn_subplots.png\")\n",
    "(g0|g1|g3).savefig(\"nifty50correlationimage1.png\") ## Check for the image in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g4 = sns.jointplot(x='NIFTY50', y='INDIAVIX', data=df5p, kind = 'scatter')\n",
    "g4 = pw.load_seaborngrid(g4, label=\"g4\")\n",
    "g5 = sns.jointplot(x='NIFTY50', y='N225', data=df6p, kind = 'scatter')\n",
    "g5 = pw.load_seaborngrid(g5, label=\"g5\")\n",
    "g6 = sns.jointplot(x='NIFTY50', y='HSI', data=df7p, kind = 'scatter')\n",
    "g6 = pw.load_seaborngrid(g6, label=\"g6\")\n",
    "(g4|g5|g6).savefig(\"nifty50correlationimage2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #============================================\n",
    "# ###   ===Do not use this method ======\n",
    "# #============================================\n",
    "\n",
    "# ## in this code NA values are dropped overall for the dataframe and not for columns in pairwise.\n",
    "# ## hence pearsonr r values are slightly different. It is adviced to drop NA values for columns pairwise unless\n",
    "# ## there are not too many NA values.\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # df1 = pd.DataFrame(np.random.rand(10, 5), columns=['Col1', 'Col2', 'Col3', 'Col4', 'Col5'])\n",
    "# # df2 = pd.DataFrame(np.random.rand(10, 5), columns=['Col1', 'Col2', 'Col3', 'Col4', 'Col5'])\n",
    "\n",
    "# dfn = df.pct_change()\n",
    "# df1=dfn.dropna(axis=0);\n",
    "# df2=dfn.dropna(axis=0);\n",
    "\n",
    "# coeffmat = np.zeros((df1.shape[1], df2.shape[1]))\n",
    "# pvalmat = np.zeros((df1.shape[1], df2.shape[1]))\n",
    "\n",
    "# for i in range(df1.shape[1]):    \n",
    "#     for j in range(df2.shape[1]):     \n",
    "#         corrtest = pearsonr(df1[df1.columns[i]], df2[df2.columns[j]])  \n",
    "\n",
    "#         coeffmat[i,j] = corrtest[0]\n",
    "#         pvalmat[i,j] = corrtest[1]\n",
    "\n",
    "# dfcoeff = pd.DataFrame(coeffmat, columns=df2.columns, index=df1.columns)\n",
    "# print(dfcoeff)\n",
    "# corr = dfcoeff\n",
    "# corr.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# dfpvals = pd.DataFrame(pvalmat, columns=df2.columns, index=df1.columns)\n",
    "# print(dfpvals)\n",
    "# corr = dfpvals\n",
    "# corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf9902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bf5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ad69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31930a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
